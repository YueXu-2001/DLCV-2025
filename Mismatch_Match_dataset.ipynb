{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f726a79a-34ef-4af4-8ea0-bcf6029121bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d2044a-bb47-422f-aedc-5281856a502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f069315d-dfaa-408e-8b9f-ed84fafd9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df545a6a-9f9a-4ae9-8d32-efc396090b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638f945-8aab-4b2b-992d-6aa783b01c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3d8450-3d3e-479f-83d8-54e904414b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac01d130-5aac-430a-accd-473509ffe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f676a95d-a10e-4711-8e46-c97ab8368e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7edc6825-f25f-4973-9ce3-cc15e8a35064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1f93ea-76ca-4e8a-bcae-5b6a8b06fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f460a3d-412a-47d4-9b8a-cf35d03398bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"C:\\Users\\Jlngo\\Deep Learning in Computer Visions\\Project\\processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3027f1e1-9678-4b52-90c4-6191fc7bf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store data from all JSON files\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90728d6a-4f9e-4322-b2ff-1da4d7a6ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):  # Ensure the file is a JSON file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data['match'] = 1\n",
    "            #print(type(data))\n",
    "            '''\n",
    "            if isinstance(data,dict) and 'Items' in data:\n",
    "                for item in data['Items']:\n",
    "                    item['match'] = 1\n",
    "            else:\n",
    "                data['match'] = 1\n",
    "            '''\n",
    "            all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b0745fa-bf34-4d3b-a60d-e4d942abd629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded: 12418\n",
      "Sample data: {'Outfit_Gender': 'female', 'Outfit_Occasion': 'Campus', 'Outfit_Style': 'Casual', 'Items': [{'Image': '10000_9712_31465287787.jpg', 'category': ['Top'], 'subcategory': ['jacket']}, {'Image': '10000_9717_31942910318.jpg', 'category': ['Pants'], 'subcategory': ['casual pants']}, {'Image': '10000_6916_30454716460.jpg', 'category': ['Shoes'], 'subcategory': ['platform shoes']}], 'match': 1}\n"
     ]
    }
   ],
   "source": [
    "#print(\"Data loaded from all JSON files:\", all_data)\n",
    "print(\"Number of files loaded:\", len(all_data))\n",
    "print(\"Sample data:\", all_data[0] if all_data else \"No data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4fe0bd6-3e94-42f2-bea3-c8d73581137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2665a51-1344-4974-baff-a6bfbd21220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [] #storing all the images for swapping \n",
    "class_data = {} #dictionary to store data by class for swapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65970cf8-5e8b-4ca2-b8cb-6ab9134aa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in all_data:\n",
    "    if isinstance(sample,dict) and 'Items' in sample:\n",
    "        #gender = sample.get('Outfit_Gender', 'Unknown')\n",
    "        #occasion = sample.get('Outfit_Occasion','Unknown')\n",
    "        style = sample.get('Outfit_Style','Unknown')\n",
    "        #print(gender,occasion,style)\n",
    "        for item in sample['Items']:\n",
    "            all_images.append((style,item['Image'],item['category'],item['subcategory'],sample))\n",
    "        if style not in class_data:\n",
    "            class_data[style] = []\n",
    "            class_data[style].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9f8d8f0-b79d-48f2-bda1-8d5a133c5e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12418"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = len(all_data)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95b5352b-dd3a-41ca-a42d-46155d135d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(count):\n",
    "    #choosing a random sample \n",
    "    i = random.randint(0,len(all_data)-1)\n",
    "    sample = all_data[i]\n",
    "    #get the original class and items \n",
    "    original_class = sample.get('Outfit_Style','Unknown')\n",
    "    original_item = sample['Items']\n",
    "    #randomly choose an item to swap \n",
    "    swap_i = random.randint(0, len(original_item) - 1)\n",
    "    item_to_swap = original_item[swap_i]\n",
    "    #randomly select another sample from a different class\n",
    "    swap_class = random.choice([cls for cls in class_data.keys() if cls != original_class])\n",
    "    swap_sample = random.choice(class_data[swap_class])\n",
    "    #get a random item from the selected swap class \n",
    "    swap_item = random.choice(swap_sample['Items'])\n",
    "    #create mismatch by swapping the images \n",
    "    new_sample = sample.copy()  # Make a copy of the sample to avoid modifying the original\n",
    "    new_sample['Items'][swap_i]['Image'] = swap_item['Image']  # Swap the image\n",
    "    # Add the \"match\" field to the mismatch sample\n",
    "    new_sample['match'] = 0  # This is a mismatch\n",
    "    # Add to mismatch_data\n",
    "    mismatch_data.append(new_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b450853d-d94d-4e9b-98a8-f3beca79f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12418\n"
     ]
    }
   ],
   "source": [
    "print(len(mismatch_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb6daf7f-a5d4-4569-b8d3-32eb971799b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: {'Outfit_Gender': 'female', 'Outfit_Occasion': 'Workplace', 'Outfit_Style': 'Elegant', 'Items': [{'Image': '10235_6908_30771792170.jpg', 'category': ['Skirt'], 'subcategory': ['dress']}, {'Image': '8046_5257_28283100161.jpg', 'category': ['Bags'], 'subcategory': ['square bag']}, {'Image': '8046_6917_26250549871.jpg', 'category': ['Shoes'], 'subcategory': ['Sandals']}], 'match': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample data:\", mismatch_data[0] if mismatch_data else \"No data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc8d961e-f248-4a62-9ad7-2e7269a426e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.extend(mismatch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d0b299d-86c9-4ad9-8d91-784e77a11d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24836"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6c3e627-81b4-4c5a-ad4a-37bd04ac4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = r\"C:\\Users\\Jlngo\\Deep Learning in Computer Visions\\Project\\dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b70ba7da-a6ea-4f37-921b-dddabec66791",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(all_data, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99d11166-be48-4d37-a5d9-a61a6cc20b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully written to C:\\Users\\Jlngo\\Deep Learning in Computer Visions\\Project\\dataset.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4db862-e80f-4721-a503-bdfae4fde972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
